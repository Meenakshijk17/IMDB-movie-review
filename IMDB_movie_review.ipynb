{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29a30836",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9dd1eee4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Probably my all-time favorite movie, a story o...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I sure would like to see a resurrection of a u...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This show was an amazing, fresh &amp; innovative i...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Encouraged by the positive comments about this...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  I thought this was a wonderful way to spend ti...  positive\n",
       "1  Probably my all-time favorite movie, a story o...  positive\n",
       "2  I sure would like to see a resurrection of a u...  positive\n",
       "3  This show was an amazing, fresh & innovative i...  negative\n",
       "4  Encouraged by the positive comments about this...  negative"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('IMDB_dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc3148f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25000 entries, 0 to 24999\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   review     25000 non-null  object\n",
      " 1   sentiment  25000 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 390.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e7ec956",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negative    12500\n",
       "positive    12500\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4733cc4d",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38b1280e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I thought this was a wonderful way to spend time on a too hot summer weekend, sitting in the air conditioned theater and watching a light-hearted comedy. The plot is simplistic, but the dialogue is witty and the characters are likable (even the well bread suspected serial killer). While some may be disappointed when they realize this is not Match Point 2: Risk Addiction, I thought it was proof that Woody Allen is still fully in control of the style many of us have grown to love.<br /><br />This was the most I\\'d laughed at one of Woody\\'s comedies in years (dare I say a decade?). While I\\'ve never been impressed with Scarlet Johanson, in this she managed to tone down her \"sexy\" image and jumped right into a average, but spirited young woman.<br /><br />This may not be the crown jewel of his career, but it was wittier than \"Devil Wears Prada\" and more interesting than \"Superman\" a great comedy to go see with friends.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.review[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb90689b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lowering the case of the reviews\n",
    "df.review = df.review.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a2bc213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing any non-word, non-space characters (punctuations)\n",
    "df.review = df.review.str.replace(\"[^\\w\\s]\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "260313cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Meenakshi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82df9941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenization\n",
    "df['review_tokens'] = df.review.apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43b35288",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Meenakshi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stopwds = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "867dfc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing stop words\n",
    "df['review_tokens'] = df['review_tokens'].apply(lambda x: [word for word in x if word not in stopwds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c62bf6fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Meenakshi\\AppData\\Roaming\\nltk_data...\n"
     ]
    }
   ],
   "source": [
    "# lemmatising the tokens\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "df['review_tokens_lemma'] = df['review_tokens'].apply(lambda x: [lemmatizer.lemmatize(token) for token in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "35777b2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review_tokens</th>\n",
       "      <th>review_tokens_lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[thought, wonderful, way, spend, time, hot, su...</td>\n",
       "      <td>[thought, wonderful, way, spend, time, hot, su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>probably my alltime favorite movie a story of ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[probably, alltime, favorite, movie, story, se...</td>\n",
       "      <td>[probably, alltime, favorite, movie, story, se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i sure would like to see a resurrection of a u...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[sure, would, like, see, resurrection, dated, ...</td>\n",
       "      <td>[sure, would, like, see, resurrection, dated, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>this show was an amazing fresh  innovative ide...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[show, amazing, fresh, innovative, idea, 70s, ...</td>\n",
       "      <td>[show, amazing, fresh, innovative, idea, 70, f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>encouraged by the positive comments about this...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[encouraged, positive, comments, film, looking...</td>\n",
       "      <td>[encouraged, positive, comment, film, looking,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment  \\\n",
       "0  i thought this was a wonderful way to spend ti...  positive   \n",
       "1  probably my alltime favorite movie a story of ...  positive   \n",
       "2  i sure would like to see a resurrection of a u...  positive   \n",
       "3  this show was an amazing fresh  innovative ide...  negative   \n",
       "4  encouraged by the positive comments about this...  negative   \n",
       "\n",
       "                                       review_tokens  \\\n",
       "0  [thought, wonderful, way, spend, time, hot, su...   \n",
       "1  [probably, alltime, favorite, movie, story, se...   \n",
       "2  [sure, would, like, see, resurrection, dated, ...   \n",
       "3  [show, amazing, fresh, innovative, idea, 70s, ...   \n",
       "4  [encouraged, positive, comments, film, looking...   \n",
       "\n",
       "                                 review_tokens_lemma  \n",
       "0  [thought, wonderful, way, spend, time, hot, su...  \n",
       "1  [probably, alltime, favorite, movie, story, se...  \n",
       "2  [sure, would, like, see, resurrection, dated, ...  \n",
       "3  [show, amazing, fresh, innovative, idea, 70, f...  \n",
       "4  [encouraged, positive, comment, film, looking,...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6958a02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing tf-idf vectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vect = TfidfVectorizer()\n",
    "\n",
    "tfidf_vect.fit(df['review_tokens_lemma'].apply(lambda x: ' '.join(x)))\n",
    "X = tfidf_vect.transform(df['review_tokens_lemma'].apply(lambda x: ' '.join(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7145f43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the target variable by mapping to 1 & 0\n",
    "y = df['sentiment'].map({'positive': 1, 'negative': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "48451b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting data into train and test (50-50 ratio as mentioned in the instructions)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4c4401a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# funtion to print the results from a cross validation\n",
    "def print_cv_results(results):\n",
    "    means = results.cv_results_['mean_test_score']\n",
    "    stds = results.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, results.cv_results_['params']):\n",
    "        print(f'{round(mean, 3)} (+/-{round(std * 2, 3)}) with {params}')\n",
    "    print(f'\\nBEST PARAMS: {results.best_params_}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9a71b285",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bccb3eea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.568 (+/-0.035) with {'max_depth': 2, 'n_estimators': 5}\n",
      "0.692 (+/-0.032) with {'max_depth': 2, 'n_estimators': 50}\n",
      "0.606 (+/-0.054) with {'max_depth': 4, 'n_estimators': 5}\n",
      "0.754 (+/-0.017) with {'max_depth': 4, 'n_estimators': 50}\n",
      "0.63 (+/-0.023) with {'max_depth': 8, 'n_estimators': 5}\n",
      "0.786 (+/-0.03) with {'max_depth': 8, 'n_estimators': 50}\n",
      "0.68 (+/-0.023) with {'max_depth': 16, 'n_estimators': 5}\n",
      "0.808 (+/-0.005) with {'max_depth': 16, 'n_estimators': 50}\n",
      "0.697 (+/-0.03) with {'max_depth': 32, 'n_estimators': 5}\n",
      "0.821 (+/-0.019) with {'max_depth': 32, 'n_estimators': 50}\n",
      "0.702 (+/-0.011) with {'max_depth': None, 'n_estimators': 5}\n",
      "0.826 (+/-0.01) with {'max_depth': None, 'n_estimators': 50}\n",
      "\n",
      "BEST PARAMS: {'max_depth': None, 'n_estimators': 50}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "parameters = {\n",
    "              'n_estimators': [5, 50],\n",
    "              'max_depth': [2, 4, 8, 16, 32, None]\n",
    "              }\n",
    "cv1 = GridSearchCV(rf, parameters, cv=5)\n",
    "cv1.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "print_cv_results(cv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1b759926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n",
      "[CV 1/2] END ......learning_rate=1, max_depth=3;, score=0.791 total time= 1.9min\n",
      "[CV 2/2] END ......learning_rate=1, max_depth=3;, score=0.800 total time= 1.9min\n",
      "[CV 1/2] END ......learning_rate=1, max_depth=5;, score=0.794 total time= 2.4min\n",
      "[CV 2/2] END ......learning_rate=1, max_depth=5;, score=0.797 total time= 2.4min\n",
      "[CV 1/2] END .....learning_rate=10, max_depth=3;, score=0.328 total time= 2.0min\n",
      "[CV 2/2] END .....learning_rate=10, max_depth=3;, score=0.495 total time= 1.9min\n",
      "[CV 1/2] END .....learning_rate=10, max_depth=5;, score=0.498 total time= 2.6min\n",
      "[CV 2/2] END .....learning_rate=10, max_depth=5;, score=0.502 total time= 2.6min\n",
      "0.795 (+/-0.01) with {'learning_rate': 1, 'max_depth': 3}\n",
      "0.795 (+/-0.004) with {'learning_rate': 1, 'max_depth': 5}\n",
      "0.411 (+/-0.168) with {'learning_rate': 10, 'max_depth': 3}\n",
      "0.5 (+/-0.005) with {'learning_rate': 10, 'max_depth': 5}\n",
      "\n",
      "BEST PARAMS: {'learning_rate': 1, 'max_depth': 3}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gb = GradientBoostingClassifier()\n",
    "parameters = {\n",
    "#     'n_estimators': [5, 50],\n",
    "    'max_depth': [3, 5],\n",
    "    'learning_rate': [1, 10]\n",
    "}\n",
    "\n",
    "cv2 = GridSearchCV(gb, parameters, cv=2, verbose=3)\n",
    "cv2.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "print_cv_results(cv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "cd8d782d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm:     Random Forest: Accuracy: 1.0; Precision: 1.0; Recall: 1.0; Latency: 530.56ms\n",
      "[[6310    0]\n",
      " [   0 6190]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      6310\n",
      "           1       1.00      1.00      1.00      6190\n",
      "\n",
      "    accuracy                           1.00     12500\n",
      "   macro avg       1.00      1.00      1.00     12500\n",
      "weighted avg       1.00      1.00      1.00     12500\n",
      "\n",
      "Algorithm: Gradient Boosting: Accuracy: 0.9292; Precision: 0.9292; Recall: 0.9293; Latency: 31.25ms\n",
      "[[5817  493]\n",
      " [ 392 5798]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.92      0.93      6310\n",
      "           1       0.92      0.94      0.93      6190\n",
      "\n",
      "    accuracy                           0.93     12500\n",
      "   macro avg       0.93      0.93      0.93     12500\n",
      "weighted avg       0.93      0.93      0.93     12500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "def evaluate(alg, model, X_data, y_data):\n",
    "    start_time = time()\n",
    "    y_pred = model.predict(X_data)\n",
    "    latency = round((time() - start_time)*1000, 2)\n",
    "    accuracy = round(accuracy_score(y_data, y_pred), 4)\n",
    "    precision = round(precision_score(y_data, y_pred, average='macro'), 4)\n",
    "    recall = round(recall_score(y_data, y_pred, average='macro'), 4)\n",
    "    print(f\"Algorithm: {alg}: Accuracy: {accuracy}; Precision: {precision}; Recall: {recall}; Latency: {latency}ms\")\n",
    "    print(confusion_matrix(y_data, y_pred))\n",
    "    print(classification_report(y_data, y_pred))\n",
    "\n",
    "evaluate(\"    Random Forest\", cv1.best_estimator_, X_train, y_train)\n",
    "evaluate(\"Gradient Boosting\", cv2.best_estimator_, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491ee990",
   "metadata": {},
   "source": [
    "Eventhough the random forest model has better metrics, it is highly overfit to the training data. Hence the best model from the above search is gradient boosting with {'learning_rate': 1, 'max_depth': 3} as parameters. It's performance on the test set is as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7919e6a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm: Best model: Gradient Boosting {'learning_rate': 1, 'max_depth': 3} \n",
      " : Accuracy: 0.8188; Precision: 0.8191; Recall: 0.8186; Latency: 22.89ms\n",
      "[[4966 1224]\n",
      " [1041 5269]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.80      0.81      6190\n",
      "           1       0.81      0.84      0.82      6310\n",
      "\n",
      "    accuracy                           0.82     12500\n",
      "   macro avg       0.82      0.82      0.82     12500\n",
      "weighted avg       0.82      0.82      0.82     12500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate(\"Best model: Gradient Boosting {'learning_rate': 1, 'max_depth': 3} \\n \", cv2.best_estimator_, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65defb05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.8 (default, Apr 13 2021, 15:08:03) [MSC v.1916 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "452b90bea1dc56bb7abd92e2828b74e7b1bfd708fd58372070ca854e487506c8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
